{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d74e7c-e1af-4a35-bd7d-e3a186433972",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from radiomics import featureextractor\n",
    "import glob\n",
    "from scipy.stats import kruskal\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.metrics import (roc_auc_score, classification_report,\n",
    "                             confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc)\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE  # 确保已安装imblearn库\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import shap\n",
    "\n",
    "# 设置随机种子，确保结果可复现\n",
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    # 如果使用PyTorch，也需要设置相关种子\n",
    "    # torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "    return seed\n",
    "\n",
    "SEED = seed_everything(42)\n",
    "\n",
    "# 定义训练集和测试集的图像和掩膜文件的文件夹路径\n",
    "# 训练集路径\n",
    "train_image_folder = \"C:/Users/YK/Desktop/train_liver\"\n",
    "train_mask_folder = \"C:/Users/YK/Desktop/train_liver-mask\"\n",
    "\n",
    "# 测试集路径\n",
    "test_image_folder = \"C:/Users/YK/Desktop/test_liver\"\n",
    "test_mask_folder = \"C:/Users/YK/Desktop/test_liver-mask\"\n",
    "\n",
    "# 创建结果保存目录\n",
    "results_dir = \"LF-LML(E)\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 初始化特征提取器\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "\n",
    "# 启用所有标准特征类\n",
    "feature_classes = [\n",
    "    'firstorder', 'glcm', 'glrlm', 'glszm',\n",
    "    'ngtdm', 'gldm', 'shape2D'  # 使用shape2D替代shape\n",
    "]\n",
    "for fc in feature_classes:\n",
    "    extractor.enableFeatureClassByName(fc)\n",
    "\n",
    "# 启用所有可用的图像类型\n",
    "image_types = [\n",
    "    'Wavelet', 'LoG', 'Square', 'SquareRoot',\n",
    "    'Logarithm', 'Exponential', 'Gradient'\n",
    "]\n",
    "for it in image_types:\n",
    "    extractor.enableImageTypeByName(it)\n",
    "\n",
    "# 配置额外参数以增加特征\n",
    "extractor.settings.update({\n",
    "    'binWidth': 25,\n",
    "    'normalize': True,\n",
    "    'force2D': True  # 确保处理为2D图像\n",
    "})\n",
    "\n",
    "# 定义函数用于提取数据集特征\n",
    "def extract_dataset_features(image_folder, mask_folder):\n",
    "    features_list = []\n",
    "    groups_list = []\n",
    "    \n",
    "    # 遍历文件夹中的文件\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith('.jpg'):\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            group_info = base_name.split('_')[0].split('F')[1]\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            \n",
    "            # 使用通配符匹配所有可能的掩膜文件\n",
    "            mask_pattern = os.path.join(mask_folder, base_name + \".nrrd\")\n",
    "            mask_files = glob.glob(mask_pattern)\n",
    "            \n",
    "            for mask_path in mask_files:\n",
    "                try:\n",
    "                    # 读取图像和掩膜\n",
    "                    image = sitk.ReadImage(image_path)\n",
    "                    mask = sitk.ReadImage(mask_path)\n",
    "                    \n",
    "                    # 维度处理\n",
    "                    if image.GetDimension() != mask.GetDimension():\n",
    "                        if image.GetDimension() == 2 and mask.GetDimension() == 3:\n",
    "                            mask = mask[:, :, 0]  # 取第一个切片\n",
    "                        else:\n",
    "                            print(f\"维度不匹配已跳过：{image_path} | {mask_path}\")\n",
    "                            continue\n",
    "                            \n",
    "                    # 图像预处理\n",
    "                    if image.GetNumberOfComponentsPerPixel() > 1:\n",
    "                        image = sitk.VectorIndexSelectionCast(image, 0, sitk.sitkUInt8)\n",
    "                    \n",
    "                    # 特征提取\n",
    "                    features = extractor.execute(image, mask)\n",
    "                    \n",
    "                    # 过滤诊断信息并保留所有特征\n",
    "                    feature_values = {\n",
    "                        k: v for k, v in features.items()\n",
    "                        if not k.startswith('diagnostics')\n",
    "                    }\n",
    "                    \n",
    "                    features_list.append(feature_values)\n",
    "                    groups_list.append(group_info)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"处理失败 {mask_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return features_list, groups_list\n",
    "\n",
    "# 提取训练集特征\n",
    "print(\"正在提取训练集特征...\")\n",
    "train_features_list, train_groups_list = extract_dataset_features(train_image_folder, train_mask_folder)\n",
    "\n",
    "# 提取测试集特征\n",
    "print(\"正在提取测试集特征...\")\n",
    "test_features_list, test_groups_list = extract_dataset_features(test_image_folder, test_mask_folder)\n",
    "\n",
    "# 将特征转换为 DataFrame\n",
    "X_train = pd.DataFrame(train_features_list)\n",
    "X_test = pd.DataFrame(test_features_list)\n",
    "\n",
    "# 将分组信息转换为 Series\n",
    "y_train = pd.Series(train_groups_list)\n",
    "y_test = pd.Series(test_groups_list)\n",
    "\n",
    "# 确保有至少3个类别\n",
    "unique_classes = np.unique(y_train)\n",
    "if len(unique_classes) < 3:\n",
    "    print(f\"警告：训练数据中只有{len(unique_classes)}个类别，需要至少3个类别进行三分类分析\")\n",
    "    # 创建模拟的三分类标签（仅用于演示，实际使用时请替换为真实数据）\n",
    "    print(\"创建模拟的三分类标签用于演示...\")\n",
    "    np.random.seed(SEED)\n",
    "    y_train = pd.Series(np.random.choice(['1', '2', '3'], size=len(y_train)))\n",
    "    unique_classes = np.unique(y_train)\n",
    "\n",
    "# 确保测试集类别与训练集一致\n",
    "test_unique = np.unique(y_test)\n",
    "for cls in test_unique:\n",
    "    if cls not in unique_classes:\n",
    "        print(f\"警告：测试集中发现训练集不存在的类别 {cls}，将其映射到最接近的类别\")\n",
    "        # 简单处理：将不存在的类别映射到第一个类别\n",
    "        y_test.replace(cls, unique_classes[0], inplace=True)\n",
    "\n",
    "# 重新编码目标变量，使其从 0 开始\n",
    "class_mapping = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "y_train = y_train.map(class_mapping)\n",
    "y_test = y_test.map(class_mapping)\n",
    "\n",
    "# 处理类别不平衡 - 只对训练集应用SMOTE\n",
    "smote = SMOTE(random_state=SEED)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------- 2. 特征筛选（仅在训练集内进行） ---------------------\n",
    "# 2.1 单变量筛选 (Kruskal-Wallis)\n",
    "significant_features = []\n",
    "for feature in X_train.columns:\n",
    "    groups = [X_train[y_train == group][feature] for group in y_train.unique()]\n",
    "    try:\n",
    "        _, p_val = kruskal(*groups)\n",
    "    except ValueError:\n",
    "        p_val = 1.0\n",
    "    if p_val < 0.05:\n",
    "        significant_features.append(feature)\n",
    "X_train_filtered = X_train[significant_features]\n",
    "\n",
    "# 2.2 去除高相关特征（相关系数>0.9）\n",
    "corr_matrix = X_train_filtered.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones_like(corr_matrix), k=1).astype(bool))\n",
    "to_drop = [col for col in upper.columns if any(upper[col] > 0.9)]\n",
    "X_train_filtered = X_train_filtered.drop(columns=to_drop)\n",
    "\n",
    "# 确保测试集也只保留筛选后的特征\n",
    "# 处理测试集中可能不存在于训练集中的特征\n",
    "test_features_to_keep = [f for f in X_train_filtered.columns if f in X_test.columns]\n",
    "missing_features = [f for f in X_train_filtered.columns if f not in X_test.columns]\n",
    "if missing_features:\n",
    "    print(f\"警告：测试集中缺少{len(missing_features)}个训练集特征，将使用默认值0填充\")\n",
    "    # 创建缺失特征并填充0\n",
    "    for f in missing_features:\n",
    "        X_test[f] = 0\n",
    "    test_features_to_keep = X_train_filtered.columns\n",
    "\n",
    "X_test_filtered = X_test[test_features_to_keep]\n",
    "\n",
    "# --------------------- 3. 特征标准化 ---------------------\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 训练集标准化（转换为数组）\n",
    "X_train_scaled_array = scaler.fit_transform(X_train_filtered)\n",
    "\n",
    "# 测试集标准化（使用训练集的均值和方差）\n",
    "X_test_scaled_array = scaler.transform(X_test_filtered)\n",
    "\n",
    "# 将标准化后的数组转换回DataFrame（保留列名）\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    X_train_scaled_array,\n",
    "    columns=X_train_filtered.columns,\n",
    "    index=X_train_filtered.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    X_test_scaled_array,\n",
    "    columns=X_test_filtered.columns,\n",
    "    index=X_test_filtered.index\n",
    ")\n",
    "\n",
    "# --------------------- 4. 使用Lasso回归进行特征选择（交叉验证） ---------------------\n",
    "# 创建 LassoCV 模型进行交叉验证\n",
    "lasso_cv = LassoCV(cv=5, alphas=np.logspace(-4, 0, 100), n_jobs=-1)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 获取最优的 alpha 值\n",
    "alpha_best = lasso_cv.alpha_\n",
    "print(f\"最优 alpha 值: {alpha_best}\")\n",
    "\n",
    "# 计算每个alpha对应的交叉验证误差和标准误差\n",
    "mse_mean = lasso_cv.mse_path_.mean(axis=1)  # 平均MSE\n",
    "mse_std = lasso_cv.mse_path_.std(axis=1)    # MSE的标准差\n",
    "\n",
    "# 计算1-SE准则下的alpha\n",
    "min_mse_idx = np.argmin(mse_mean)\n",
    "min_mse = mse_mean[min_mse_idx]\n",
    "mse_1se = min_mse + mse_std[min_mse_idx]\n",
    "alpha_1se = np.max(lasso_cv.alphas_[mse_mean <= mse_1se])\n",
    "\n",
    "print(f\"1-SE alpha 值: {alpha_1se}\")\n",
    "\n",
    "# 创建不同正则化强度的 Lasso 模型\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "coefs = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "# 可视化系数随正则化强度的变化\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(X_train_scaled.shape[1]):\n",
    "    plt.plot(alphas, [coef[i] for coef in coefs], marker='o', markersize=3, alpha=0.6)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Log lambda', fontsize=14)\n",
    "plt.ylabel('Coefficients', fontsize=14)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend([])\n",
    "plt.savefig('./lasso_coef_path(LF-liver).tif', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 进行特征筛选\n",
    "lasso = Lasso(alpha=alpha_best)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 获取非零系数对应的特征索引\n",
    "selected_features_indices = np.nonzero(lasso.coef_)[0]\n",
    "\n",
    "# 打印筛选出的特征名称\n",
    "feature_names = X_train_scaled.columns\n",
    "selected_feature_names = [feature_names[i] for i in selected_features_indices]\n",
    "print(f\"筛选出的特征数量: {len(selected_feature_names)}\")\n",
    "print(\"筛选出的特征:\", selected_feature_names)\n",
    "\n",
    "# 交叉验证曲线可视化\n",
    "error_band_width = 0.1  # 可调整为任意正数，如1.5、2.0等\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lasso_cv.alphas_, mse_mean, color='red', linewidth=2, label='平均MSE')\n",
    "\n",
    "# 方法1：使用垂直线段表示误差带（原方法）\n",
    "for i in range(len(mse_mean)):\n",
    "    plt.plot([lasso_cv.alphas_[i], lasso_cv.alphas_[i]], \n",
    "             [mse_mean[i] - error_band_width * mse_std[i], mse_mean[i] + error_band_width * mse_std[i]], \n",
    "             color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# 添加两条竖线\n",
    "plt.axvline(x=alpha_best, color='gray', linestyle='--', label=f'最优 alpha: {alpha_best:.6f}')\n",
    "plt.axvline(x=alpha_1se, color='gray', linestyle='--', label=f'1-SE alpha: {alpha_1se:.6f}')\n",
    "\n",
    "# 更改y轴取值范围\n",
    "#plt.ylim([0.19, 0.23])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Log (λ)', fontsize=14)\n",
    "plt.ylabel('Mean Squared Error', fontsize=14)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.savefig('./lasso_cv_curve(LF-liver).tif', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 使用筛选后的特征\n",
    "X_train_selected = X_train_scaled[selected_feature_names]\n",
    "X_test_selected = X_test_scaled[selected_feature_names]  # 确保测试集使用相同特征\n",
    "\n",
    "print(f\"最终特征维度: {X_train_selected.shape}\")\n",
    "\n",
    "# --------------------- 使用SHAP库生成热力图 ---------------------\n",
    "# 确保Lasso模型已正确拟合\n",
    "lasso = Lasso(alpha=alpha_best)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 验证系数存在\n",
    "print(\"Lasso系数形状:\", lasso.coef_.shape)\n",
    "\n",
    "# 直接使用系数计算SHAP值\n",
    "shap_values = X_train_scaled * lasso.coef_\n",
    "\n",
    "# 筛选非零系数特征（仅用于可视化）\n",
    "non_zero_features = X_train_scaled.columns[lasso.coef_ != 0]\n",
    "non_zero_indices = [i for i, col in enumerate(X_train_scaled.columns) if col in non_zero_features]\n",
    "non_zero_shap_values = shap_values.iloc[:, non_zero_indices]  # 使用DataFrame索引\n",
    "non_zero_data = X_train_scaled[non_zero_features]\n",
    "\n",
    "# 创建图形对象并指定为当前图形\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 生成SHAP图（关闭自动显示）\n",
    "shap.summary_plot(non_zero_shap_values.values, non_zero_data, plot_type=\"dot\", show=False)\n",
    "#plt.title('SHAP Feature Importance (Lasso Regression)', fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图形并关闭\n",
    "fig.savefig('./SHAP_Feature_Importance(LF-liver).tif', dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)  # 关闭图形以释放资源\n",
    "\n",
    "# 定义交叉验证对象，确保每次分割一致\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# 随机森林模型参数选择\n",
    "param_grid_rf = [\n",
    "    {'n_estimators': [200, 300], 'max_depth': [15, 20], 'min_samples_split': [2, 3], 'min_samples_leaf': [1, 2]}\n",
    "]\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=SEED), param_grid_rf, cv=cv)\n",
    "grid_search_rf.fit(X_train_selected, y_train)\n",
    "clf_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# 决策树模型参数选择\n",
    "param_grid_dt = [\n",
    "    {'max_depth': [10, 15], 'min_samples_split': [2, 3], 'min_samples_leaf': [1, 2]}\n",
    "]\n",
    "grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=SEED), param_grid_dt, cv=cv)\n",
    "grid_search_dt.fit(X_train_selected, y_train)\n",
    "clf_dt = grid_search_dt.best_estimator_\n",
    "\n",
    "# 逻辑回归模型参数选择 - 确保支持多分类\n",
    "param_grid_lg = [\n",
    "    {'C': [0.1, 1, 10], 'penalty': ['l2', 'none']}\n",
    "]\n",
    "grid_search_lg = GridSearchCV(\n",
    "    LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED, max_iter=1000), \n",
    "    param_grid_lg, cv=cv\n",
    ")\n",
    "grid_search_lg.fit(X_train_selected, y_train)\n",
    "clf_lg = grid_search_lg.best_estimator_\n",
    "\n",
    "# SVM模型参数选择 - 确保支持多分类\n",
    "param_grid_svm = [\n",
    "    {'C': [1, 10, 100], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "]\n",
    "grid_search_svm = GridSearchCV(SVC(probability=True, random_state=SEED, decision_function_shape='ovo'), param_grid_svm, cv=cv)\n",
    "grid_search_svm.fit(X_train_selected, y_train)\n",
    "clf_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "# GBM模型参数选择\n",
    "param_grid_gbm = [\n",
    "    {'n_estimators': [200, 300], 'learning_rate': [0.05, 0.1], 'max_depth': [5, 7]}\n",
    "]\n",
    "grid_search_gbm = GridSearchCV(GradientBoostingClassifier(random_state=SEED), param_grid_gbm, cv=cv)\n",
    "grid_search_gbm.fit(X_train_selected, y_train)\n",
    "clf_gbm = grid_search_gbm.best_estimator_\n",
    "\n",
    "# XGBoost 模型参数选择 - 确保支持多分类\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'objective': ['multi:softprob'],  # 多分类问题\n",
    "    'num_class': [len(unique_classes)]  # 类别数量\n",
    "}\n",
    "grid_search_xgb = GridSearchCV(xgb.XGBClassifier(random_state=SEED), param_grid_xgb, cv=cv)\n",
    "grid_search_xgb.fit(X_train_selected, y_train)\n",
    "clf_xgb = grid_search_xgb.best_estimator_\n",
    "\n",
    "# 创建堆叠分类器进行集成学习\n",
    "estimators = [\n",
    "    ('rf', clf_rf),\n",
    "    ('dt', clf_dt),\n",
    "    ('lg', clf_lg),\n",
    "    ('svm', clf_svm),\n",
    "    ('gbm', clf_gbm),\n",
    "    ('xgb', clf_xgb)\n",
    "]\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators, \n",
    "    final_estimator=LogisticRegression(random_state=SEED, max_iter=1000), \n",
    "    cv=cv\n",
    ")\n",
    "stacking_clf.fit(X_train_selected, y_train)\n",
    "\n",
    "# 计算AUC的95%置信区间（使用DeLong方法）\n",
    "def calculate_auc_ci(y_true, y_score, alpha=0.95):\n",
    "    from scipy import stats\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # 计算AUC\n",
    "    auc = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    # 计算AUC的方差（DeLong方法）\n",
    "    y_true = np.array(y_true)\n",
    "    y_score = np.array(y_score)\n",
    "    \n",
    "    # 正例和反例的分数\n",
    "    pos_scores = y_score[y_true == 1]\n",
    "    neg_scores = y_score[y_true == 0]\n",
    "    \n",
    "    # 计算AUC的方差\n",
    "    n1 = len(pos_scores)\n",
    "    n2 = len(neg_scores)\n",
    "    \n",
    "    # 计算所有可能的正负样本对的比较结果\n",
    "    tx = np.tile(pos_scores, (n2, 1))\n",
    "    ty = np.tile(neg_scores, (n1, 1)).T\n",
    "    \n",
    "    # 计算AUC的方差\n",
    "    p = np.mean(tx > ty) + 0.5 * np.mean(tx == ty)\n",
    "    \n",
    "    # 计算协方差矩阵\n",
    "    pair_matrix = tx > ty\n",
    "    pair_matrix_equal = tx == ty\n",
    "    \n",
    "    # 计算第一个方差分量\n",
    "    variance_p1 = np.sum((np.mean(pair_matrix, axis=1) - p) ** 2) / (n1 - 1)\n",
    "    \n",
    "    # 计算第二个方差分量\n",
    "    variance_p2 = np.sum((np.mean(pair_matrix, axis=0) - p) ** 2) / (n2 - 1)\n",
    "    \n",
    "    # 计算AUC的标准误差\n",
    "    se_auc = np.sqrt((variance_p1 / n1) + (variance_p2 / n2))\n",
    "    \n",
    "    # 计算置信区间\n",
    "    z = stats.norm.ppf(1 - (1 - alpha) / 2)\n",
    "    lower = max(0, auc - z * se_auc)\n",
    "    upper = min(1, auc + z * se_auc)\n",
    "    \n",
    "    return auc, lower, upper\n",
    "\n",
    "# 计算二分类指标的95%置信区间（使用bootstrap方法）\n",
    "def calculate_metrics_ci(y_true, y_pred, n_bootstraps=1000, alpha=0.95):\n",
    "    from sklearn.utils import resample\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    # 存储每次bootstrap的结果\n",
    "    sensitivity_bootstraps = []\n",
    "    specificity_bootstraps = []\n",
    "    ppv_bootstraps = []\n",
    "    npv_bootstraps = []\n",
    "    lr_pos_bootstraps = []\n",
    "    lr_neg_bootstraps = []\n",
    "    \n",
    "    # 执行bootstrap\n",
    "    for i in range(n_bootstraps):\n",
    "        # 有放回地抽样\n",
    "        indices = resample(range(len(y_true)))\n",
    "        y_true_bs = y_true[indices]\n",
    "        y_pred_bs = y_pred[indices]\n",
    "        \n",
    "        # 计算混淆矩阵\n",
    "        cm = confusion_matrix(y_true_bs, y_pred_bs)\n",
    "        \n",
    "        if cm.shape == (1, 1):  # 处理只有一个类别的情况\n",
    "            sensitivity = 1.0\n",
    "            specificity = 1.0\n",
    "            ppv = 1.0\n",
    "            npv = 1.0\n",
    "            lr_pos = float('inf')\n",
    "            lr_neg = 0.0\n",
    "        else:\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            \n",
    "            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "            ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "            lr_pos = sensitivity / (1 - specificity) if (1 - specificity) > 0 else float('inf')\n",
    "            lr_neg = (1 - sensitivity) / specificity if specificity > 0 else float('inf')\n",
    "        \n",
    "        # 存储结果\n",
    "        sensitivity_bootstraps.append(sensitivity)\n",
    "        specificity_bootstraps.append(specificity)\n",
    "        ppv_bootstraps.append(ppv)\n",
    "        npv_bootstraps.append(npv)\n",
    "        lr_pos_bootstraps.append(lr_pos)\n",
    "        lr_neg_bootstraps.append(lr_neg)\n",
    "    \n",
    "    # 计算置信区间\n",
    "    def ci_interval(bootstraps):\n",
    "        sorted_bootstraps = np.sort(bootstraps)\n",
    "        lower = sorted_bootstraps[int((1 - alpha) / 2 * n_bootstraps)]\n",
    "        upper = sorted_bootstraps[int((1 + alpha) / 2 * n_bootstraps)]\n",
    "        return lower, upper\n",
    "    \n",
    "    sensitivity_ci = ci_interval(sensitivity_bootstraps)\n",
    "    specificity_ci = ci_interval(specificity_bootstraps)\n",
    "    ppv_ci = ci_interval(ppv_bootstraps)\n",
    "    npv_ci = ci_interval(npv_bootstraps)\n",
    "    lr_pos_ci = ci_interval(lr_pos_bootstraps)\n",
    "    lr_neg_ci = ci_interval(lr_neg_bootstraps)\n",
    "    \n",
    "    return {\n",
    "        'Sensitivity': (np.mean(sensitivity_bootstraps), sensitivity_ci),\n",
    "        'Specificity': (np.mean(specificity_bootstraps), specificity_ci),\n",
    "        'PPV': (np.mean(ppv_bootstraps), ppv_ci),\n",
    "        'NPV': (np.mean(npv_bootstraps), npv_ci),\n",
    "        'LR+': (np.mean(lr_pos_bootstraps), lr_pos_ci),\n",
    "        'LR-': (np.mean(lr_neg_bootstraps), lr_neg_ci)\n",
    "    }\n",
    "\n",
    "# 计算模型的 ROC 曲线及 AUC 值的函数，增加置信区间计算\n",
    "def calculate_roc_auc(model_name, y_pred_proba, y_test):\n",
    "    unique_groups = np.unique(y_test)\n",
    "    num_classes = len(unique_groups)\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    roc_auc_ci = {}\n",
    "    \n",
    "    # 多分类情况\n",
    "    for class_idx, group in enumerate(unique_groups):\n",
    "        # 针对每个真实分组计算对应的ROC曲线和AUC值\n",
    "        fpr[group], tpr[group], _ = roc_curve(y_test == group, y_pred_proba[:, class_idx])\n",
    "        roc_auc[group], lower, upper = calculate_auc_ci(y_test == group, y_pred_proba[:, class_idx])\n",
    "        roc_auc_ci[group] = (lower, upper)\n",
    "    \n",
    "    # 打印AUC值及其置信区间\n",
    "    print(f\"\\n{model_name}模型的AUC值:\")\n",
    "    for group in unique_groups:\n",
    "        print(f\"类别 {group}: {roc_auc[group]:.4f} (95% CI: {roc_auc_ci[group][0]:.4f}-{roc_auc_ci[group][1]:.4f})\")\n",
    "    \n",
    "    return fpr, tpr, roc_auc, roc_auc_ci  # 返回值增加roc_auc_ci\n",
    "\n",
    "# 计算模型性能指标（敏感性、特异性、PPV、NPV、LR+、LR-）\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    \n",
    "    # 获取唯一类别\n",
    "    classes = np.unique(y_true)\n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    # 初始化结果字典\n",
    "    metrics = {}\n",
    "    \n",
    "    # 计算每个类别的指标\n",
    "    for i, cls in enumerate(classes):\n",
    "        # 创建二分类标签：当前类别为正类，其他为负类\n",
    "        y_true_binary = (y_true == cls).astype(int)\n",
    "        y_pred_binary = (y_pred == cls).astype(int)\n",
    "        \n",
    "        # 计算混淆矩阵\n",
    "        cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
    "        \n",
    "        if cm.shape == (1, 1):  # 处理只有一个类别的情况\n",
    "            if y_true_binary[0] == 1:\n",
    "                # 所有样本都是正类\n",
    "                tp = cm[0, 0]\n",
    "                fn = 0\n",
    "                fp = 0\n",
    "                tn = 0\n",
    "            else:\n",
    "                # 所有样本都是负类\n",
    "                tp = 0\n",
    "                fn = 0\n",
    "                fp = 0\n",
    "                tn = cm[0, 0]\n",
    "        else:\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        # 计算各项指标\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "        lr_pos = sensitivity / (1 - specificity) if (1 - specificity) > 0 else float('inf')\n",
    "        lr_neg = (1 - sensitivity) / specificity if specificity > 0 else float('inf')\n",
    "        \n",
    "        # 存储结果\n",
    "        metrics[cls] = {\n",
    "            'Sensitivity': sensitivity,\n",
    "            'Specificity': specificity,\n",
    "            'PPV': ppv,\n",
    "            'NPV': npv,\n",
    "            'LR+': lr_pos,\n",
    "            'LR-': lr_neg\n",
    "        }\n",
    "    \n",
    "    # 计算总体准确率\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    metrics['overall'] = {'Accuracy': accuracy}\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 获取各模型在测试集上的预测结果和预测概率（使用筛选后的特征）\n",
    "y_pred_rf = clf_rf.predict(X_test_selected)\n",
    "y_pred_proba_rf = clf_rf.predict_proba(X_test_selected)\n",
    "y_pred_dt = clf_dt.predict(X_test_selected)\n",
    "y_pred_proba_dt = clf_dt.predict_proba(X_test_selected)\n",
    "y_pred_lg = clf_lg.predict(X_test_selected)\n",
    "y_pred_proba_lg = clf_lg.predict_proba(X_test_selected)\n",
    "y_pred_svm = clf_svm.predict(X_test_selected)\n",
    "y_pred_proba_svm = clf_svm.predict_proba(X_test_selected)\n",
    "y_pred_gbm = clf_gbm.predict(X_test_selected)\n",
    "y_pred_proba_gbm = clf_gbm.predict_proba(X_test_selected)\n",
    "y_pred_xgb = clf_xgb.predict(X_test_selected)\n",
    "y_pred_proba_xgb = clf_xgb.predict_proba(X_test_selected)\n",
    "y_pred_stacking = stacking_clf.predict(X_test_selected)\n",
    "y_pred_proba_stacking = stacking_clf.predict_proba(X_test_selected)\n",
    "\n",
    "# 获取各模型在训练集上的预测结果和预测概率\n",
    "y_pred_train_rf = clf_rf.predict(X_train_selected)\n",
    "y_pred_proba_train_rf = clf_rf.predict_proba(X_train_selected)\n",
    "y_pred_train_dt = clf_dt.predict(X_train_selected)\n",
    "y_pred_proba_train_dt = clf_dt.predict_proba(X_train_selected)\n",
    "y_pred_train_lg = clf_lg.predict(X_train_selected)\n",
    "y_pred_proba_train_lg = clf_lg.predict_proba(X_train_selected)\n",
    "y_pred_train_svm = clf_svm.predict(X_train_selected)\n",
    "y_pred_proba_train_svm = clf_svm.predict_proba(X_train_selected)\n",
    "y_pred_train_gbm = clf_gbm.predict(X_train_selected)\n",
    "y_pred_proba_train_gbm = clf_gbm.predict_proba(X_train_selected)\n",
    "y_pred_train_xgb = clf_xgb.predict(X_train_selected)\n",
    "y_pred_proba_train_xgb = clf_xgb.predict_proba(X_train_selected)\n",
    "y_pred_train_stacking = stacking_clf.predict(X_train_selected)\n",
    "y_pred_proba_train_stacking = stacking_clf.predict_proba(X_train_selected)\n",
    "\n",
    "# 计算各模型的 ROC 曲线及 AUC 值 - 测试集\n",
    "fpr_rf, tpr_rf, roc_auc_rf, roc_auc_ci_rf = calculate_roc_auc('RandomForest', y_pred_proba_rf, y_test)\n",
    "fpr_dt, tpr_dt, roc_auc_dt, roc_auc_ci_dt = calculate_roc_auc('DecisionTree', y_pred_proba_dt, y_test)\n",
    "fpr_lg, tpr_lg, roc_auc_lg, roc_auc_ci_lg = calculate_roc_auc('LogisticRegression', y_pred_proba_lg, y_test)\n",
    "fpr_svm, tpr_svm, roc_auc_svm, roc_auc_ci_svm = calculate_roc_auc('SVM', y_pred_proba_svm, y_test)\n",
    "fpr_gbm, tpr_gbm, roc_auc_gbm, roc_auc_ci_gbm = calculate_roc_auc('GBM', y_pred_proba_gbm, y_test)\n",
    "fpr_xgb, tpr_xgb, roc_auc_xgb, roc_auc_ci_xgb = calculate_roc_auc('XGBoost', y_pred_proba_xgb, y_test)\n",
    "fpr_stacking, tpr_stacking, roc_auc_stacking, roc_auc_ci_stacking = calculate_roc_auc('StackingClassifier', y_pred_proba_stacking, y_test)\n",
    "\n",
    "# 计算各模型的 ROC 曲线及 AUC 值 - 训练集\n",
    "fpr_train_rf, tpr_train_rf, roc_auc_train_rf, roc_auc_ci_train_rf = calculate_roc_auc('RandomForest', y_pred_proba_train_rf, y_train)\n",
    "fpr_train_dt, tpr_train_dt, roc_auc_train_dt, roc_auc_ci_train_dt = calculate_roc_auc('DecisionTree', y_pred_proba_train_dt, y_train)\n",
    "fpr_train_lg, tpr_train_lg, roc_auc_train_lg, roc_auc_ci_train_lg = calculate_roc_auc('LogisticRegression', y_pred_proba_train_lg, y_train)\n",
    "fpr_train_svm, tpr_train_svm, roc_auc_train_svm, roc_auc_ci_train_svm = calculate_roc_auc('SVM', y_pred_proba_train_svm, y_train)\n",
    "fpr_train_gbm, tpr_train_gbm, roc_auc_train_gbm, roc_auc_ci_train_gbm = calculate_roc_auc('GBM', y_pred_proba_train_gbm, y_train)\n",
    "fpr_train_xgb, tpr_train_xgb, roc_auc_train_xgb, roc_auc_ci_train_xgb = calculate_roc_auc('XGBoost', y_pred_proba_train_xgb, y_train)\n",
    "fpr_train_stacking, tpr_train_stacking, roc_auc_train_stacking, roc_auc_ci_train_stacking = calculate_roc_auc('StackingClassifier', y_pred_proba_train_stacking, y_train)\n",
    "\n",
    "# 绘制测试集上所有类别的 ROC 曲线\n",
    "plt.figure(figsize=(12, 8))\n",
    "line_styles = ['-', '--', '-.', ':']\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
    "markers = ['o', 's', '^', '*', 'D', 'X', 'v']\n",
    "\n",
    "# 获取唯一的类别列表\n",
    "unique_classes = np.unique(y_test)\n",
    "num_classes = len(unique_classes)\n",
    "\n",
    "# 多分类问题，为每个类别绘制所有模型的曲线\n",
    "for group_idx, group in enumerate(unique_classes):\n",
    "    # 随机森林模型的曲线设置\n",
    "    plt.plot(fpr_rf[group], tpr_rf[group], label=f'Random Forest -  {group}',\n",
    "             lw=2, c=colors[0], marker=markers[0], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 决策树模型的曲线设置\n",
    "    plt.plot(fpr_dt[group], tpr_dt[group], label=f'Decision Tree -  {group}',\n",
    "             lw=2, c=colors[1], marker=markers[1], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 逻辑回归模型的曲线设置\n",
    "    plt.plot(fpr_lg[group], tpr_lg[group], label=f'LogisticRegression -  {group}',\n",
    "             lw=2, c=colors[2], marker=markers[2], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # SVM模型的曲线设置\n",
    "    plt.plot(fpr_svm[group], tpr_svm[group], label=f'SVM -  {group}',\n",
    "             lw=2, c=colors[3], marker=markers[3], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # GBM模型的曲线设置\n",
    "    plt.plot(fpr_gbm[group], tpr_gbm[group], \n",
    "             label=f'GBM -  {group}',\n",
    "             lw=2, c=colors[4], marker=markers[4], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # XGBoost 模型的曲线设置\n",
    "    plt.plot(fpr_xgb[group], tpr_xgb[group], \n",
    "             label=f'XGBoost -  {group}',\n",
    "             lw=2, c=colors[5], marker=markers[5], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 堆叠分类器模型的曲线设置\n",
    "    plt.plot(fpr_stacking[group], tpr_stacking[group], \n",
    "             label=f'StackingClassifier -  {group}',\n",
    "             lw=2, c=colors[6], marker=markers[6], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "#plt.title('ROC Curves for All Classes (Test Set)')\n",
    "plt.legend(loc=\"lower right\", fontsize='small')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.savefig('./LF-LML-roc(test).tif', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练集上所有类别的 ROC 曲线\n",
    "plt.figure(figsize=(12, 8))\n",
    "line_styles = ['-', '--', '-.', ':']\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
    "markers = ['o', 's', '^', '*', 'D', 'X', 'v']\n",
    "\n",
    "# 获取唯一的类别列表\n",
    "unique_classes = np.unique(y_train)\n",
    "num_classes = len(unique_classes)\n",
    "\n",
    "# 多分类问题，为每个类别绘制所有模型的曲线\n",
    "for group_idx, group in enumerate(unique_classes):\n",
    "    # 随机森林模型的曲线设置\n",
    "    plt.plot(fpr_train_rf[group], tpr_train_rf[group], label=f'Random Forest -  {group}',\n",
    "             lw=2, c=colors[0], marker=markers[0], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 决策树模型的曲线设置\n",
    "    plt.plot(fpr_train_dt[group], tpr_train_dt[group], label=f'Decision Tree -  {group}',\n",
    "             lw=2, c=colors[1], marker=markers[1], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 逻辑回归模型的曲线设置\n",
    "    plt.plot(fpr_train_lg[group], tpr_train_lg[group], label=f'LogisticRegression -  {group}',\n",
    "             lw=2, c=colors[2], marker=markers[2], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # SVM模型的曲线设置\n",
    "    plt.plot(fpr_train_svm[group], tpr_train_svm[group], label=f'SVM -  {group}',\n",
    "             lw=2, c=colors[3], marker=markers[3], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # GBM模型的曲线设置\n",
    "    plt.plot(fpr_train_gbm[group], tpr_train_gbm[group], \n",
    "             label=f'GBM -  {group}',\n",
    "             lw=2, c=colors[4], marker=markers[4], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # XGBoost 模型的曲线设置\n",
    "    plt.plot(fpr_train_xgb[group], tpr_train_xgb[group], \n",
    "             label=f'XGBoost -  {group}',\n",
    "             lw=2, c=colors[5], marker=markers[5], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 堆叠分类器模型的曲线设置\n",
    "    plt.plot(fpr_train_stacking[group], tpr_train_stacking[group], \n",
    "             label=f'StackingClassifier -  {group}',\n",
    "             lw=2, c=colors[6], marker=markers[6], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "#plt.title('ROC Curves for All Classes (Training Set)')\n",
    "plt.legend(loc=\"lower right\", fontsize='small')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.savefig('./LF-LML-roc(train).tif', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 计算并打印各模型的性能指标\n",
    "def print_model_metrics(model_name, y_true, y_pred, dataset_type):\n",
    "    metrics = calculate_metrics(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} Model ({dataset_type}):\")\n",
    "    \n",
    "    # 获取所有类别键（排除'overall'）\n",
    "    class_keys = [k for k in metrics.keys() if k != 'overall']\n",
    "    \n",
    "    # 尝试对类别键进行排序\n",
    "    try:\n",
    "        # 尝试数值排序\n",
    "        class_keys = sorted(class_keys, key=lambda x: int(x))\n",
    "    except (ValueError, TypeError):\n",
    "        # 如果无法数值排序，则进行字符串排序\n",
    "        class_keys = sorted(class_keys, key=lambda x: str(x))\n",
    "    \n",
    "    # 打印每个类别的指标\n",
    "    for cls in class_keys:\n",
    "        print(f\"\\n  类别 {cls}:\")\n",
    "        print(f\"    Sensitivity: {metrics[cls]['Sensitivity']:.4f}\")\n",
    "        print(f\"    Specificity: {metrics[cls]['Specificity']:.4f}\")\n",
    "        print(f\"    Positive Predictive Value (PPV): {metrics[cls]['PPV']:.4f}\")\n",
    "        print(f\"    Negative Predictive Value (NPV): {metrics[cls]['NPV']:.4f}\")\n",
    "        print(f\"    Positive Likelihood Ratio (LR+): {metrics[cls]['LR+']:.4f}\")\n",
    "        print(f\"    Negative Likelihood Ratio (LR-): {metrics[cls]['LR-']:.4f}\")\n",
    "    \n",
    "    # 打印总体准确率\n",
    "    print(f\"\\n  总体准确率: {metrics['overall']['Accuracy']:.4f}\")\n",
    "\n",
    "# 打印测试集指标\n",
    "print_model_metrics(\"Random Forest\", y_test, y_pred_rf, \"Test Set\")\n",
    "print_model_metrics(\"Decision Tree\", y_test, y_pred_dt, \"Test Set\")\n",
    "print_model_metrics(\"Logistic Regression\", y_test, y_pred_lg, \"Test Set\")\n",
    "print_model_metrics(\"SVM\", y_test, y_pred_svm, \"Test Set\")\n",
    "print_model_metrics(\"Gradient Boosting\", y_test, y_pred_gbm, \"Test Set\")\n",
    "print_model_metrics(\"XGBoost\", y_test, y_pred_xgb, \"Test Set\")\n",
    "print_model_metrics(\"Stacking Classifier\", y_test, y_pred_stacking, \"Test Set\")\n",
    "\n",
    "# 打印训练集指标\n",
    "print_model_metrics(\"Random Forest\", y_train, y_pred_train_rf, \"Training Set\")\n",
    "print_model_metrics(\"Decision Tree\", y_train, y_pred_train_dt, \"Training Set\")\n",
    "print_model_metrics(\"Logistic Regression\", y_train, y_pred_train_lg, \"Training Set\")\n",
    "print_model_metrics(\"SVM\", y_train, y_pred_train_svm, \"Training Set\")\n",
    "print_model_metrics(\"Gradient Boosting\", y_train, y_pred_train_gbm, \"Training Set\")\n",
    "print_model_metrics(\"XGBoost\", y_train, y_pred_train_xgb, \"Training Set\")\n",
    "print_model_metrics(\"Stacking Classifier\", y_train, y_pred_train_stacking, \"Training Set\")\n",
    "\n",
    "# 保存所有模型的测试集结果，按分类保存\n",
    "for model_name, y_pred_proba, y_pred in zip(\n",
    "    ['RandomForest', 'DecisionTree', 'LogisticRegression', 'SVM', 'GBM', 'XGBoost', 'StackingClassifier'],\n",
    "    [y_pred_proba_rf, y_pred_proba_dt, y_pred_proba_lg, y_pred_proba_svm, y_pred_proba_gbm, y_pred_proba_xgb, y_pred_proba_stacking],\n",
    "    [y_pred_rf, y_pred_dt, y_pred_lg, y_pred_svm, y_pred_gbm, y_pred_xgb, y_pred_stacking]\n",
    "):\n",
    "    # 创建模型目录\n",
    "    model_dir = os.path.join(results_dir, \"test\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # 保存原始预测结果\n",
    "    custom_name = f'LF-LML-{model_name}(test)'\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_true.npy'), y_test)\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_proba.npy'), y_pred_proba)\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_pred.npy'), y_pred)\n",
    "    print(f\"已保存 {custom_name} 模型的测试集原始结果\")\n",
    "    \n",
    "    # 按分类保存预测结果\n",
    "    for class_idx, class_name in enumerate(unique_classes):\n",
    "        class_dir = os.path.join(model_dir, f\"class_{class_name}\")\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        \n",
    "        # 为当前类别创建二分类标签\n",
    "        y_true_binary = (y_test == class_name).astype(int)\n",
    "        y_pred_binary = (y_pred == class_name).astype(int)\n",
    "        y_proba_binary = y_pred_proba[:, class_idx]\n",
    "        \n",
    "        # 保存二分类结果\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_true.npy'), y_true_binary)\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_proba.npy'), y_proba_binary)\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_pred.npy'), y_pred_binary)\n",
    "        print(f\"已保存 {custom_name} 模型类别 {class_name} 的测试集二分类结果\")\n",
    "\n",
    "# 保存所有模型的训练集结果，按分类保存\n",
    "for model_name, y_pred_proba, y_pred in zip(\n",
    "    ['RandomForest', 'DecisionTree', 'LogisticRegression', 'SVM', 'GBM', 'XGBoost', 'StackingClassifier'],\n",
    "    [y_pred_proba_train_rf, y_pred_proba_train_dt, y_pred_proba_train_lg, y_pred_proba_train_svm, y_pred_proba_train_gbm, y_pred_proba_train_xgb, y_pred_proba_train_stacking],\n",
    "    [y_pred_train_rf, y_pred_train_dt, y_pred_train_lg, y_pred_train_svm, y_pred_train_gbm, y_pred_train_xgb, y_pred_train_stacking]\n",
    "):\n",
    "    # 创建模型目录\n",
    "    model_dir = os.path.join(results_dir, \"train\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # 保存原始预测结果\n",
    "    custom_name = f'LF-LML-{model_name}(train)'\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_true.npy'), y_train)\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_proba.npy'), y_pred_proba)\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_pred.npy'), y_pred)\n",
    "    print(f\"已保存 {custom_name} 模型的训练集原始结果\")\n",
    "    \n",
    "    # 按分类保存预测结果\n",
    "    for class_idx, class_name in enumerate(unique_classes):\n",
    "        class_dir = os.path.join(model_dir, f\"class_{class_name}\")\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        \n",
    "        # 为当前类别创建二分类标签\n",
    "        y_true_binary = (y_train == class_name).astype(int)\n",
    "        y_pred_binary = (y_pred == class_name).astype(int)\n",
    "        y_proba_binary = y_pred_proba[:, class_idx]\n",
    "        \n",
    "        # 保存二分类结果\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_true.npy'), y_true_binary)\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_proba.npy'), y_proba_binary)\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_pred.npy'), y_pred_binary)\n",
    "        print(f\"已保存 {custom_name} 模型类别 {class_name} 的训练集二分类结果\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed76243-fc1c-45ee-b1fa-8f1529a137cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from radiomics import featureextractor\n",
    "import glob\n",
    "from scipy.stats import kruskal\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.metrics import (roc_auc_score, classification_report,\n",
    "                             confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc)\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE  # 确保已安装imblearn库\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import shap\n",
    "\n",
    "# 设置随机种子，确保结果可复现\n",
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    # 如果使用PyTorch，也需要设置相关种子\n",
    "    # torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "    return seed\n",
    "\n",
    "SEED = seed_everything(42)\n",
    "\n",
    "# 定义训练集和测试集的图像和掩膜文件的文件夹路径\n",
    "# 训练集路径\n",
    "train_image_folder = \"C:/Users/YK/Desktop/train_spleen\"\n",
    "train_mask_folder = \"C:/Users/YK/Desktop/train_spleen-mask\"\n",
    "\n",
    "# 测试集路径\n",
    "test_image_folder = \"C:/Users/YK/Desktop/test_spleen\"\n",
    "test_mask_folder = \"C:/Users/YK/Desktop/test_spleen-mask\"\n",
    "\n",
    "# 创建结果保存目录\n",
    "results_dir = \"LF-LML(E)\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 初始化特征提取器\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "\n",
    "# 启用所有标准特征类\n",
    "feature_classes = [\n",
    "    'firstorder', 'glcm', 'glrlm', 'glszm',\n",
    "    'ngtdm', 'gldm', 'shape2D'  # 使用shape2D替代shape\n",
    "]\n",
    "for fc in feature_classes:\n",
    "    extractor.enableFeatureClassByName(fc)\n",
    "\n",
    "# 启用所有可用的图像类型\n",
    "image_types = [\n",
    "    'Wavelet', 'LoG', 'Square', 'SquareRoot',\n",
    "    'Logarithm', 'Exponential', 'Gradient'\n",
    "]\n",
    "for it in image_types:\n",
    "    extractor.enableImageTypeByName(it)\n",
    "\n",
    "# 配置额外参数以增加特征\n",
    "extractor.settings.update({\n",
    "    'binWidth': 25,\n",
    "    'normalize': True,\n",
    "    'force2D': True  # 确保处理为2D图像\n",
    "})\n",
    "\n",
    "# 定义函数用于提取数据集特征\n",
    "def extract_dataset_features(image_folder, mask_folder):\n",
    "    features_list = []\n",
    "    groups_list = []\n",
    "    \n",
    "    # 遍历文件夹中的文件\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith('.jpg'):\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            group_info = base_name.split('_')[0].split('F')[1]\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            \n",
    "            # 使用通配符匹配所有可能的掩膜文件\n",
    "            mask_pattern = os.path.join(mask_folder, base_name + \".nrrd\")\n",
    "            mask_files = glob.glob(mask_pattern)\n",
    "            \n",
    "            for mask_path in mask_files:\n",
    "                try:\n",
    "                    # 读取图像和掩膜\n",
    "                    image = sitk.ReadImage(image_path)\n",
    "                    mask = sitk.ReadImage(mask_path)\n",
    "                    \n",
    "                    # 维度处理\n",
    "                    if image.GetDimension() != mask.GetDimension():\n",
    "                        if image.GetDimension() == 2 and mask.GetDimension() == 3:\n",
    "                            mask = mask[:, :, 0]  # 取第一个切片\n",
    "                        else:\n",
    "                            print(f\"维度不匹配已跳过：{image_path} | {mask_path}\")\n",
    "                            continue\n",
    "                            \n",
    "                    # 图像预处理\n",
    "                    if image.GetNumberOfComponentsPerPixel() > 1:\n",
    "                        image = sitk.VectorIndexSelectionCast(image, 0, sitk.sitkUInt8)\n",
    "                    \n",
    "                    # 特征提取\n",
    "                    features = extractor.execute(image, mask)\n",
    "                    \n",
    "                    # 过滤诊断信息并保留所有特征\n",
    "                    feature_values = {\n",
    "                        k: v for k, v in features.items()\n",
    "                        if not k.startswith('diagnostics')\n",
    "                    }\n",
    "                    \n",
    "                    features_list.append(feature_values)\n",
    "                    groups_list.append(group_info)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"处理失败 {mask_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return features_list, groups_list\n",
    "\n",
    "# 提取训练集特征\n",
    "print(\"正在提取训练集特征...\")\n",
    "train_features_list, train_groups_list = extract_dataset_features(train_image_folder, train_mask_folder)\n",
    "\n",
    "# 提取测试集特征\n",
    "print(\"正在提取测试集特征...\")\n",
    "test_features_list, test_groups_list = extract_dataset_features(test_image_folder, test_mask_folder)\n",
    "\n",
    "# 将特征转换为 DataFrame\n",
    "X_train = pd.DataFrame(train_features_list)\n",
    "X_test = pd.DataFrame(test_features_list)\n",
    "\n",
    "# 将分组信息转换为 Series\n",
    "y_train = pd.Series(train_groups_list)\n",
    "y_test = pd.Series(test_groups_list)\n",
    "\n",
    "# 确保有至少3个类别\n",
    "unique_classes = np.unique(y_train)\n",
    "if len(unique_classes) < 3:\n",
    "    print(f\"警告：训练数据中只有{len(unique_classes)}个类别，需要至少3个类别进行三分类分析\")\n",
    "    # 创建模拟的三分类标签（仅用于演示，实际使用时请替换为真实数据）\n",
    "    print(\"创建模拟的三分类标签用于演示...\")\n",
    "    np.random.seed(SEED)\n",
    "    y_train = pd.Series(np.random.choice(['1', '2', '3'], size=len(y_train)))\n",
    "    unique_classes = np.unique(y_train)\n",
    "\n",
    "# 确保测试集类别与训练集一致\n",
    "test_unique = np.unique(y_test)\n",
    "for cls in test_unique:\n",
    "    if cls not in unique_classes:\n",
    "        print(f\"警告：测试集中发现训练集不存在的类别 {cls}，将其映射到最接近的类别\")\n",
    "        # 简单处理：将不存在的类别映射到第一个类别\n",
    "        y_test.replace(cls, unique_classes[0], inplace=True)\n",
    "\n",
    "# 重新编码目标变量，使其从 0 开始\n",
    "class_mapping = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "y_train = y_train.map(class_mapping)\n",
    "y_test = y_test.map(class_mapping)\n",
    "\n",
    "# 处理类别不平衡 - 只对训练集应用SMOTE\n",
    "smote = SMOTE(random_state=SEED)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------- 2. 特征筛选（仅在训练集内进行） ---------------------\n",
    "# 2.1 单变量筛选 (Kruskal-Wallis)\n",
    "significant_features = []\n",
    "for feature in X_train.columns:\n",
    "    groups = [X_train[y_train == group][feature] for group in y_train.unique()]\n",
    "    try:\n",
    "        _, p_val = kruskal(*groups)\n",
    "    except ValueError:\n",
    "        p_val = 1.0\n",
    "    if p_val < 0.05:\n",
    "        significant_features.append(feature)\n",
    "X_train_filtered = X_train[significant_features]\n",
    "\n",
    "# 2.2 去除高相关特征（相关系数>0.9）\n",
    "corr_matrix = X_train_filtered.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones_like(corr_matrix), k=1).astype(bool))\n",
    "to_drop = [col for col in upper.columns if any(upper[col] > 0.9)]\n",
    "X_train_filtered = X_train_filtered.drop(columns=to_drop)\n",
    "\n",
    "# 确保测试集也只保留筛选后的特征\n",
    "# 处理测试集中可能不存在于训练集中的特征\n",
    "test_features_to_keep = [f for f in X_train_filtered.columns if f in X_test.columns]\n",
    "missing_features = [f for f in X_train_filtered.columns if f not in X_test.columns]\n",
    "if missing_features:\n",
    "    print(f\"警告：测试集中缺少{len(missing_features)}个训练集特征，将使用默认值0填充\")\n",
    "    # 创建缺失特征并填充0\n",
    "    for f in missing_features:\n",
    "        X_test[f] = 0\n",
    "    test_features_to_keep = X_train_filtered.columns\n",
    "\n",
    "X_test_filtered = X_test[test_features_to_keep]\n",
    "\n",
    "# --------------------- 3. 特征标准化 ---------------------\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 训练集标准化（转换为数组）\n",
    "X_train_scaled_array = scaler.fit_transform(X_train_filtered)\n",
    "\n",
    "# 测试集标准化（使用训练集的均值和方差）\n",
    "X_test_scaled_array = scaler.transform(X_test_filtered)\n",
    "\n",
    "# 将标准化后的数组转换回DataFrame（保留列名）\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    X_train_scaled_array,\n",
    "    columns=X_train_filtered.columns,\n",
    "    index=X_train_filtered.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    X_test_scaled_array,\n",
    "    columns=X_test_filtered.columns,\n",
    "    index=X_test_filtered.index\n",
    ")\n",
    "\n",
    "# --------------------- 4. 使用Lasso回归进行特征选择（交叉验证） ---------------------\n",
    "# 创建 LassoCV 模型进行交叉验证\n",
    "lasso_cv = LassoCV(cv=5, alphas=np.logspace(-4, 0, 100), n_jobs=-1)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 获取最优的 alpha 值\n",
    "alpha_best = lasso_cv.alpha_\n",
    "print(f\"最优 alpha 值: {alpha_best}\")\n",
    "\n",
    "# 计算每个alpha对应的交叉验证误差和标准误差\n",
    "mse_mean = lasso_cv.mse_path_.mean(axis=1)  # 平均MSE\n",
    "mse_std = lasso_cv.mse_path_.std(axis=1)    # MSE的标准差\n",
    "\n",
    "# 计算1-SE准则下的alpha\n",
    "min_mse_idx = np.argmin(mse_mean)\n",
    "min_mse = mse_mean[min_mse_idx]\n",
    "mse_1se = min_mse + mse_std[min_mse_idx]\n",
    "alpha_1se = np.max(lasso_cv.alphas_[mse_mean <= mse_1se])\n",
    "\n",
    "print(f\"1-SE alpha 值: {alpha_1se}\")\n",
    "\n",
    "# 创建不同正则化强度的 Lasso 模型\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "coefs = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "# 可视化系数随正则化强度的变化\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(X_train_scaled.shape[1]):\n",
    "    plt.plot(alphas, [coef[i] for coef in coefs], marker='o', markersize=3, alpha=0.6)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Log lambda', fontsize=14)\n",
    "plt.ylabel('Coefficients', fontsize=14)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend([])\n",
    "plt.savefig('./lasso_coef_path(LF-spleen).tif', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 进行特征筛选\n",
    "lasso = Lasso(alpha=alpha_best)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 获取非零系数对应的特征索引\n",
    "selected_features_indices = np.nonzero(lasso.coef_)[0]\n",
    "\n",
    "# 打印筛选出的特征名称\n",
    "feature_names = X_train_scaled.columns\n",
    "selected_feature_names = [feature_names[i] for i in selected_features_indices]\n",
    "print(f\"筛选出的特征数量: {len(selected_feature_names)}\")\n",
    "print(\"筛选出的特征:\", selected_feature_names)\n",
    "\n",
    "# 交叉验证曲线可视化\n",
    "error_band_width = 0.1  # 可调整为任意正数，如1.5、2.0等\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lasso_cv.alphas_, mse_mean, color='red', linewidth=2, label='平均MSE')\n",
    "\n",
    "# 方法1：使用垂直线段表示误差带（原方法）\n",
    "for i in range(len(mse_mean)):\n",
    "    plt.plot([lasso_cv.alphas_[i], lasso_cv.alphas_[i]], \n",
    "             [mse_mean[i] - error_band_width * mse_std[i], mse_mean[i] + error_band_width * mse_std[i]], \n",
    "             color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# 添加两条竖线\n",
    "plt.axvline(x=alpha_best, color='gray', linestyle='--', label=f'最优 alpha: {alpha_best:.6f}')\n",
    "plt.axvline(x=alpha_1se, color='gray', linestyle='--', label=f'1-SE alpha: {alpha_1se:.6f}')\n",
    "\n",
    "# 更改y轴取值范围\n",
    "#plt.ylim([0.19, 0.23])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Log (λ)', fontsize=14)\n",
    "plt.ylabel('Mean Squared Error', fontsize=14)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.savefig('./lasso_cv_curve(LF-spleen).tif', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 使用筛选后的特征\n",
    "X_train_selected = X_train_scaled[selected_feature_names]\n",
    "X_test_selected = X_test_scaled[selected_feature_names]  # 确保测试集使用相同特征\n",
    "\n",
    "print(f\"最终特征维度: {X_train_selected.shape}\")\n",
    "\n",
    "# --------------------- 使用SHAP库生成热力图 ---------------------\n",
    "# 确保Lasso模型已正确拟合\n",
    "lasso = Lasso(alpha=alpha_best)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 验证系数存在\n",
    "print(\"Lasso系数形状:\", lasso.coef_.shape)\n",
    "\n",
    "# 直接使用系数计算SHAP值\n",
    "shap_values = X_train_scaled * lasso.coef_\n",
    "\n",
    "# 筛选非零系数特征（仅用于可视化）\n",
    "non_zero_features = X_train_scaled.columns[lasso.coef_ != 0]\n",
    "non_zero_indices = [i for i, col in enumerate(X_train_scaled.columns) if col in non_zero_features]\n",
    "non_zero_shap_values = shap_values.iloc[:, non_zero_indices]  # 使用DataFrame索引\n",
    "non_zero_data = X_train_scaled[non_zero_features]\n",
    "\n",
    "# 创建图形对象并指定为当前图形\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 生成SHAP图（关闭自动显示）\n",
    "shap.summary_plot(non_zero_shap_values.values, non_zero_data, plot_type=\"dot\", show=False)\n",
    "#plt.title('SHAP Feature Importance (Lasso Regression)', fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图形并关闭\n",
    "fig.savefig('./SHAP_Feature_Importance(LF-spleen).tif', dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)  # 关闭图形以释放资源\n",
    "\n",
    "# 定义交叉验证对象，确保每次分割一致\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# 随机森林模型参数选择\n",
    "param_grid_rf = [\n",
    "    {'n_estimators': [200, 300], 'max_depth': [15, 20], 'min_samples_split': [2, 3], 'min_samples_leaf': [1, 2]}\n",
    "]\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=SEED), param_grid_rf, cv=cv)\n",
    "grid_search_rf.fit(X_train_selected, y_train)\n",
    "clf_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# 决策树模型参数选择\n",
    "param_grid_dt = [\n",
    "    {'max_depth': [10, 15], 'min_samples_split': [2, 3], 'min_samples_leaf': [1, 2]}\n",
    "]\n",
    "grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=SEED), param_grid_dt, cv=cv)\n",
    "grid_search_dt.fit(X_train_selected, y_train)\n",
    "clf_dt = grid_search_dt.best_estimator_\n",
    "\n",
    "# 逻辑回归模型参数选择 - 确保支持多分类\n",
    "param_grid_lg = [\n",
    "    {'C': [0.1, 1, 10], 'penalty': ['l2', 'none']}\n",
    "]\n",
    "grid_search_lg = GridSearchCV(\n",
    "    LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED, max_iter=1000), \n",
    "    param_grid_lg, cv=cv\n",
    ")\n",
    "grid_search_lg.fit(X_train_selected, y_train)\n",
    "clf_lg = grid_search_lg.best_estimator_\n",
    "\n",
    "# SVM模型参数选择 - 确保支持多分类\n",
    "param_grid_svm = [\n",
    "    {'C': [1, 10, 100], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "]\n",
    "grid_search_svm = GridSearchCV(SVC(probability=True, random_state=SEED, decision_function_shape='ovo'), param_grid_svm, cv=cv)\n",
    "grid_search_svm.fit(X_train_selected, y_train)\n",
    "clf_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "# GBM模型参数选择\n",
    "param_grid_gbm = [\n",
    "    {'n_estimators': [200, 300], 'learning_rate': [0.05, 0.1], 'max_depth': [5, 7]}\n",
    "]\n",
    "grid_search_gbm = GridSearchCV(GradientBoostingClassifier(random_state=SEED), param_grid_gbm, cv=cv)\n",
    "grid_search_gbm.fit(X_train_selected, y_train)\n",
    "clf_gbm = grid_search_gbm.best_estimator_\n",
    "\n",
    "# XGBoost 模型参数选择 - 确保支持多分类\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'objective': ['multi:softprob'],  # 多分类问题\n",
    "    'num_class': [len(unique_classes)]  # 类别数量\n",
    "}\n",
    "grid_search_xgb = GridSearchCV(xgb.XGBClassifier(random_state=SEED), param_grid_xgb, cv=cv)\n",
    "grid_search_xgb.fit(X_train_selected, y_train)\n",
    "clf_xgb = grid_search_xgb.best_estimator_\n",
    "\n",
    "# 创建堆叠分类器进行集成学习\n",
    "estimators = [\n",
    "    ('rf', clf_rf),\n",
    "    ('dt', clf_dt),\n",
    "    ('lg', clf_lg),\n",
    "    ('svm', clf_svm),\n",
    "    ('gbm', clf_gbm),\n",
    "    ('xgb', clf_xgb)\n",
    "]\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators, \n",
    "    final_estimator=LogisticRegression(random_state=SEED, max_iter=1000), \n",
    "    cv=cv\n",
    ")\n",
    "stacking_clf.fit(X_train_selected, y_train)\n",
    "\n",
    "# 计算AUC的95%置信区间（使用DeLong方法）\n",
    "def calculate_auc_ci(y_true, y_score, alpha=0.95):\n",
    "    from scipy import stats\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # 计算AUC\n",
    "    auc = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    # 计算AUC的方差（DeLong方法）\n",
    "    y_true = np.array(y_true)\n",
    "    y_score = np.array(y_score)\n",
    "    \n",
    "    # 正例和反例的分数\n",
    "    pos_scores = y_score[y_true == 1]\n",
    "    neg_scores = y_score[y_true == 0]\n",
    "    \n",
    "    # 计算AUC的方差\n",
    "    n1 = len(pos_scores)\n",
    "    n2 = len(neg_scores)\n",
    "    \n",
    "    # 计算所有可能的正负样本对的比较结果\n",
    "    tx = np.tile(pos_scores, (n2, 1))\n",
    "    ty = np.tile(neg_scores, (n1, 1)).T\n",
    "    \n",
    "    # 计算AUC的方差\n",
    "    p = np.mean(tx > ty) + 0.5 * np.mean(tx == ty)\n",
    "    \n",
    "    # 计算协方差矩阵\n",
    "    pair_matrix = tx > ty\n",
    "    pair_matrix_equal = tx == ty\n",
    "    \n",
    "    # 计算第一个方差分量\n",
    "    variance_p1 = np.sum((np.mean(pair_matrix, axis=1) - p) ** 2) / (n1 - 1)\n",
    "    \n",
    "    # 计算第二个方差分量\n",
    "    variance_p2 = np.sum((np.mean(pair_matrix, axis=0) - p) ** 2) / (n2 - 1)\n",
    "    \n",
    "    # 计算AUC的标准误差\n",
    "    se_auc = np.sqrt((variance_p1 / n1) + (variance_p2 / n2))\n",
    "    \n",
    "    # 计算置信区间\n",
    "    z = stats.norm.ppf(1 - (1 - alpha) / 2)\n",
    "    lower = max(0, auc - z * se_auc)\n",
    "    upper = min(1, auc + z * se_auc)\n",
    "    \n",
    "    return auc, lower, upper\n",
    "\n",
    "# 计算二分类指标的95%置信区间（使用bootstrap方法）\n",
    "def calculate_metrics_ci(y_true, y_pred, n_bootstraps=1000, alpha=0.95):\n",
    "    from sklearn.utils import resample\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    # 存储每次bootstrap的结果\n",
    "    sensitivity_bootstraps = []\n",
    "    specificity_bootstraps = []\n",
    "    ppv_bootstraps = []\n",
    "    npv_bootstraps = []\n",
    "    lr_pos_bootstraps = []\n",
    "    lr_neg_bootstraps = []\n",
    "    \n",
    "    # 执行bootstrap\n",
    "    for i in range(n_bootstraps):\n",
    "        # 有放回地抽样\n",
    "        indices = resample(range(len(y_true)))\n",
    "        y_true_bs = y_true[indices]\n",
    "        y_pred_bs = y_pred[indices]\n",
    "        \n",
    "        # 计算混淆矩阵\n",
    "        cm = confusion_matrix(y_true_bs, y_pred_bs)\n",
    "        \n",
    "        if cm.shape == (1, 1):  # 处理只有一个类别的情况\n",
    "            sensitivity = 1.0\n",
    "            specificity = 1.0\n",
    "            ppv = 1.0\n",
    "            npv = 1.0\n",
    "            lr_pos = float('inf')\n",
    "            lr_neg = 0.0\n",
    "        else:\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            \n",
    "            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "            ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "            lr_pos = sensitivity / (1 - specificity) if (1 - specificity) > 0 else float('inf')\n",
    "            lr_neg = (1 - sensitivity) / specificity if specificity > 0 else float('inf')\n",
    "        \n",
    "        # 存储结果\n",
    "        sensitivity_bootstraps.append(sensitivity)\n",
    "        specificity_bootstraps.append(specificity)\n",
    "        ppv_bootstraps.append(ppv)\n",
    "        npv_bootstraps.append(npv)\n",
    "        lr_pos_bootstraps.append(lr_pos)\n",
    "        lr_neg_bootstraps.append(lr_neg)\n",
    "    \n",
    "    # 计算置信区间\n",
    "    def ci_interval(bootstraps):\n",
    "        sorted_bootstraps = np.sort(bootstraps)\n",
    "        lower = sorted_bootstraps[int((1 - alpha) / 2 * n_bootstraps)]\n",
    "        upper = sorted_bootstraps[int((1 + alpha) / 2 * n_bootstraps)]\n",
    "        return lower, upper\n",
    "    \n",
    "    sensitivity_ci = ci_interval(sensitivity_bootstraps)\n",
    "    specificity_ci = ci_interval(specificity_bootstraps)\n",
    "    ppv_ci = ci_interval(ppv_bootstraps)\n",
    "    npv_ci = ci_interval(npv_bootstraps)\n",
    "    lr_pos_ci = ci_interval(lr_pos_bootstraps)\n",
    "    lr_neg_ci = ci_interval(lr_neg_bootstraps)\n",
    "    \n",
    "    return {\n",
    "        'Sensitivity': (np.mean(sensitivity_bootstraps), sensitivity_ci),\n",
    "        'Specificity': (np.mean(specificity_bootstraps), specificity_ci),\n",
    "        'PPV': (np.mean(ppv_bootstraps), ppv_ci),\n",
    "        'NPV': (np.mean(npv_bootstraps), npv_ci),\n",
    "        'LR+': (np.mean(lr_pos_bootstraps), lr_pos_ci),\n",
    "        'LR-': (np.mean(lr_neg_bootstraps), lr_neg_ci)\n",
    "    }\n",
    "\n",
    "# 计算模型的 ROC 曲线及 AUC 值的函数，增加置信区间计算\n",
    "def calculate_roc_auc(model_name, y_pred_proba, y_test):\n",
    "    unique_groups = np.unique(y_test)\n",
    "    num_classes = len(unique_groups)\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    roc_auc_ci = {}\n",
    "    \n",
    "    # 多分类情况\n",
    "    for class_idx, group in enumerate(unique_groups):\n",
    "        # 针对每个真实分组计算对应的ROC曲线和AUC值\n",
    "        fpr[group], tpr[group], _ = roc_curve(y_test == group, y_pred_proba[:, class_idx])\n",
    "        roc_auc[group], lower, upper = calculate_auc_ci(y_test == group, y_pred_proba[:, class_idx])\n",
    "        roc_auc_ci[group] = (lower, upper)\n",
    "    \n",
    "    # 打印AUC值及其置信区间\n",
    "    print(f\"\\n{model_name}模型的AUC值:\")\n",
    "    for group in unique_groups:\n",
    "        print(f\"类别 {group}: {roc_auc[group]:.4f} (95% CI: {roc_auc_ci[group][0]:.4f}-{roc_auc_ci[group][1]:.4f})\")\n",
    "    \n",
    "    return fpr, tpr, roc_auc, roc_auc_ci  # 返回值增加roc_auc_ci\n",
    "\n",
    "# 计算模型性能指标（敏感性、特异性、PPV、NPV、LR+、LR-）\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    \n",
    "    # 获取唯一类别\n",
    "    classes = np.unique(y_true)\n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    # 初始化结果字典\n",
    "    metrics = {}\n",
    "    \n",
    "    # 计算每个类别的指标\n",
    "    for i, cls in enumerate(classes):\n",
    "        # 创建二分类标签：当前类别为正类，其他为负类\n",
    "        y_true_binary = (y_true == cls).astype(int)\n",
    "        y_pred_binary = (y_pred == cls).astype(int)\n",
    "        \n",
    "        # 计算混淆矩阵\n",
    "        cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
    "        \n",
    "        if cm.shape == (1, 1):  # 处理只有一个类别的情况\n",
    "            if y_true_binary[0] == 1:\n",
    "                # 所有样本都是正类\n",
    "                tp = cm[0, 0]\n",
    "                fn = 0\n",
    "                fp = 0\n",
    "                tn = 0\n",
    "            else:\n",
    "                # 所有样本都是负类\n",
    "                tp = 0\n",
    "                fn = 0\n",
    "                fp = 0\n",
    "                tn = cm[0, 0]\n",
    "        else:\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        # 计算各项指标\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "        lr_pos = sensitivity / (1 - specificity) if (1 - specificity) > 0 else float('inf')\n",
    "        lr_neg = (1 - sensitivity) / specificity if specificity > 0 else float('inf')\n",
    "        \n",
    "        # 存储结果\n",
    "        metrics[cls] = {\n",
    "            'Sensitivity': sensitivity,\n",
    "            'Specificity': specificity,\n",
    "            'PPV': ppv,\n",
    "            'NPV': npv,\n",
    "            'LR+': lr_pos,\n",
    "            'LR-': lr_neg\n",
    "        }\n",
    "    \n",
    "    # 计算总体准确率\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    metrics['overall'] = {'Accuracy': accuracy}\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 获取各模型在测试集上的预测结果和预测概率（使用筛选后的特征）\n",
    "y_pred_rf = clf_rf.predict(X_test_selected)\n",
    "y_pred_proba_rf = clf_rf.predict_proba(X_test_selected)\n",
    "y_pred_dt = clf_dt.predict(X_test_selected)\n",
    "y_pred_proba_dt = clf_dt.predict_proba(X_test_selected)\n",
    "y_pred_lg = clf_lg.predict(X_test_selected)\n",
    "y_pred_proba_lg = clf_lg.predict_proba(X_test_selected)\n",
    "y_pred_svm = clf_svm.predict(X_test_selected)\n",
    "y_pred_proba_svm = clf_svm.predict_proba(X_test_selected)\n",
    "y_pred_gbm = clf_gbm.predict(X_test_selected)\n",
    "y_pred_proba_gbm = clf_gbm.predict_proba(X_test_selected)\n",
    "y_pred_xgb = clf_xgb.predict(X_test_selected)\n",
    "y_pred_proba_xgb = clf_xgb.predict_proba(X_test_selected)\n",
    "y_pred_stacking = stacking_clf.predict(X_test_selected)\n",
    "y_pred_proba_stacking = stacking_clf.predict_proba(X_test_selected)\n",
    "\n",
    "# 获取各模型在训练集上的预测结果和预测概率\n",
    "y_pred_train_rf = clf_rf.predict(X_train_selected)\n",
    "y_pred_proba_train_rf = clf_rf.predict_proba(X_train_selected)\n",
    "y_pred_train_dt = clf_dt.predict(X_train_selected)\n",
    "y_pred_proba_train_dt = clf_dt.predict_proba(X_train_selected)\n",
    "y_pred_train_lg = clf_lg.predict(X_train_selected)\n",
    "y_pred_proba_train_lg = clf_lg.predict_proba(X_train_selected)\n",
    "y_pred_train_svm = clf_svm.predict(X_train_selected)\n",
    "y_pred_proba_train_svm = clf_svm.predict_proba(X_train_selected)\n",
    "y_pred_train_gbm = clf_gbm.predict(X_train_selected)\n",
    "y_pred_proba_train_gbm = clf_gbm.predict_proba(X_train_selected)\n",
    "y_pred_train_xgb = clf_xgb.predict(X_train_selected)\n",
    "y_pred_proba_train_xgb = clf_xgb.predict_proba(X_train_selected)\n",
    "y_pred_train_stacking = stacking_clf.predict(X_train_selected)\n",
    "y_pred_proba_train_stacking = stacking_clf.predict_proba(X_train_selected)\n",
    "\n",
    "# 计算各模型的 ROC 曲线及 AUC 值 - 测试集\n",
    "fpr_rf, tpr_rf, roc_auc_rf, roc_auc_ci_rf = calculate_roc_auc('RandomForest', y_pred_proba_rf, y_test)\n",
    "fpr_dt, tpr_dt, roc_auc_dt, roc_auc_ci_dt = calculate_roc_auc('DecisionTree', y_pred_proba_dt, y_test)\n",
    "fpr_lg, tpr_lg, roc_auc_lg, roc_auc_ci_lg = calculate_roc_auc('LogisticRegression', y_pred_proba_lg, y_test)\n",
    "fpr_svm, tpr_svm, roc_auc_svm, roc_auc_ci_svm = calculate_roc_auc('SVM', y_pred_proba_svm, y_test)\n",
    "fpr_gbm, tpr_gbm, roc_auc_gbm, roc_auc_ci_gbm = calculate_roc_auc('GBM', y_pred_proba_gbm, y_test)\n",
    "fpr_xgb, tpr_xgb, roc_auc_xgb, roc_auc_ci_xgb = calculate_roc_auc('XGBoost', y_pred_proba_xgb, y_test)\n",
    "fpr_stacking, tpr_stacking, roc_auc_stacking, roc_auc_ci_stacking = calculate_roc_auc('StackingClassifier', y_pred_proba_stacking, y_test)\n",
    "\n",
    "# 计算各模型的 ROC 曲线及 AUC 值 - 训练集\n",
    "fpr_train_rf, tpr_train_rf, roc_auc_train_rf, roc_auc_ci_train_rf = calculate_roc_auc('RandomForest', y_pred_proba_train_rf, y_train)\n",
    "fpr_train_dt, tpr_train_dt, roc_auc_train_dt, roc_auc_ci_train_dt = calculate_roc_auc('DecisionTree', y_pred_proba_train_dt, y_train)\n",
    "fpr_train_lg, tpr_train_lg, roc_auc_train_lg, roc_auc_ci_train_lg = calculate_roc_auc('LogisticRegression', y_pred_proba_train_lg, y_train)\n",
    "fpr_train_svm, tpr_train_svm, roc_auc_train_svm, roc_auc_ci_train_svm = calculate_roc_auc('SVM', y_pred_proba_train_svm, y_train)\n",
    "fpr_train_gbm, tpr_train_gbm, roc_auc_train_gbm, roc_auc_ci_train_gbm = calculate_roc_auc('GBM', y_pred_proba_train_gbm, y_train)\n",
    "fpr_train_xgb, tpr_train_xgb, roc_auc_train_xgb, roc_auc_ci_train_xgb = calculate_roc_auc('XGBoost', y_pred_proba_train_xgb, y_train)\n",
    "fpr_train_stacking, tpr_train_stacking, roc_auc_train_stacking, roc_auc_ci_train_stacking = calculate_roc_auc('StackingClassifier', y_pred_proba_train_stacking, y_train)\n",
    "\n",
    "# 绘制测试集上所有类别的 ROC 曲线\n",
    "plt.figure(figsize=(12, 8))\n",
    "line_styles = ['-', '--', '-.', ':']\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
    "markers = ['o', 's', '^', '*', 'D', 'X', 'v']\n",
    "\n",
    "# 获取唯一的类别列表\n",
    "unique_classes = np.unique(y_test)\n",
    "num_classes = len(unique_classes)\n",
    "\n",
    "# 多分类问题，为每个类别绘制所有模型的曲线\n",
    "for group_idx, group in enumerate(unique_classes):\n",
    "    # 随机森林模型的曲线设置\n",
    "    plt.plot(fpr_rf[group], tpr_rf[group], label=f'Random Forest -  {group}',\n",
    "             lw=2, c=colors[0], marker=markers[0], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 决策树模型的曲线设置\n",
    "    plt.plot(fpr_dt[group], tpr_dt[group], label=f'Decision Tree -  {group}',\n",
    "             lw=2, c=colors[1], marker=markers[1], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 逻辑回归模型的曲线设置\n",
    "    plt.plot(fpr_lg[group], tpr_lg[group], label=f'LogisticRegression -  {group}',\n",
    "             lw=2, c=colors[2], marker=markers[2], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # SVM模型的曲线设置\n",
    "    plt.plot(fpr_svm[group], tpr_svm[group], label=f'SVM -  {group}',\n",
    "             lw=2, c=colors[3], marker=markers[3], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # GBM模型的曲线设置\n",
    "    plt.plot(fpr_gbm[group], tpr_gbm[group], \n",
    "             label=f'GBM -  {group}',\n",
    "             lw=2, c=colors[4], marker=markers[4], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # XGBoost 模型的曲线设置\n",
    "    plt.plot(fpr_xgb[group], tpr_xgb[group], \n",
    "             label=f'XGBoost -  {group}',\n",
    "             lw=2, c=colors[5], marker=markers[5], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 堆叠分类器模型的曲线设置\n",
    "    plt.plot(fpr_stacking[group], tpr_stacking[group], \n",
    "             label=f'StackingClassifier -  {group}',\n",
    "             lw=2, c=colors[6], marker=markers[6], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "#plt.title('ROC Curves for All Classes (Test Set)')\n",
    "plt.legend(loc=\"lower right\", fontsize='small')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.savefig('./LF-SML-roc(test).tif', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练集上所有类别的 ROC 曲线\n",
    "plt.figure(figsize=(12, 8))\n",
    "line_styles = ['-', '--', '-.', ':']\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
    "markers = ['o', 's', '^', '*', 'D', 'X', 'v']\n",
    "\n",
    "# 获取唯一的类别列表\n",
    "unique_classes = np.unique(y_train)\n",
    "num_classes = len(unique_classes)\n",
    "\n",
    "# 多分类问题，为每个类别绘制所有模型的曲线\n",
    "for group_idx, group in enumerate(unique_classes):\n",
    "    # 随机森林模型的曲线设置\n",
    "    plt.plot(fpr_train_rf[group], tpr_train_rf[group], label=f'Random Forest -  {group}',\n",
    "             lw=2, c=colors[0], marker=markers[0], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 决策树模型的曲线设置\n",
    "    plt.plot(fpr_train_dt[group], tpr_train_dt[group], label=f'Decision Tree -  {group}',\n",
    "             lw=2, c=colors[1], marker=markers[1], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 逻辑回归模型的曲线设置\n",
    "    plt.plot(fpr_train_lg[group], tpr_train_lg[group], label=f'LogisticRegression -  {group}',\n",
    "             lw=2, c=colors[2], marker=markers[2], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # SVM模型的曲线设置\n",
    "    plt.plot(fpr_train_svm[group], tpr_train_svm[group], label=f'SVM -  {group}',\n",
    "             lw=2, c=colors[3], marker=markers[3], linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # GBM模型的曲线设置\n",
    "    plt.plot(fpr_train_gbm[group], tpr_train_gbm[group], \n",
    "             label=f'GBM -  {group}',\n",
    "             lw=2, c=colors[4], marker=markers[4], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # XGBoost 模型的曲线设置\n",
    "    plt.plot(fpr_train_xgb[group], tpr_train_xgb[group], \n",
    "             label=f'XGBoost -  {group}',\n",
    "             lw=2, c=colors[5], marker=markers[5], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "    # 堆叠分类器模型的曲线设置\n",
    "    plt.plot(fpr_train_stacking[group], tpr_train_stacking[group], \n",
    "             label=f'StackingClassifier -  {group}',\n",
    "             lw=2, c=colors[6], marker=markers[6], \n",
    "             linestyle=line_styles[group_idx % len(line_styles)])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "#plt.title('ROC Curves for All Classes (Training Set)')\n",
    "plt.legend(loc=\"lower right\", fontsize='small')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.savefig('./LF-SML-roc(train).tif', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 计算并打印各模型的性能指标\n",
    "def print_model_metrics(model_name, y_true, y_pred, dataset_type):\n",
    "    metrics = calculate_metrics(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} Model ({dataset_type}):\")\n",
    "    \n",
    "    # 获取所有类别键（排除'overall'）\n",
    "    class_keys = [k for k in metrics.keys() if k != 'overall']\n",
    "    \n",
    "    # 尝试对类别键进行排序\n",
    "    try:\n",
    "        # 尝试数值排序\n",
    "        class_keys = sorted(class_keys, key=lambda x: int(x))\n",
    "    except (ValueError, TypeError):\n",
    "        # 如果无法数值排序，则进行字符串排序\n",
    "        class_keys = sorted(class_keys, key=lambda x: str(x))\n",
    "    \n",
    "    # 打印每个类别的指标\n",
    "    for cls in class_keys:\n",
    "        print(f\"\\n  类别 {cls}:\")\n",
    "        print(f\"    Sensitivity: {metrics[cls]['Sensitivity']:.4f}\")\n",
    "        print(f\"    Specificity: {metrics[cls]['Specificity']:.4f}\")\n",
    "        print(f\"    Positive Predictive Value (PPV): {metrics[cls]['PPV']:.4f}\")\n",
    "        print(f\"    Negative Predictive Value (NPV): {metrics[cls]['NPV']:.4f}\")\n",
    "        print(f\"    Positive Likelihood Ratio (LR+): {metrics[cls]['LR+']:.4f}\")\n",
    "        print(f\"    Negative Likelihood Ratio (LR-): {metrics[cls]['LR-']:.4f}\")\n",
    "    \n",
    "    # 打印总体准确率\n",
    "    print(f\"\\n  总体准确率: {metrics['overall']['Accuracy']:.4f}\")\n",
    "\n",
    "# 打印测试集指标\n",
    "print_model_metrics(\"Random Forest\", y_test, y_pred_rf, \"Test Set\")\n",
    "print_model_metrics(\"Decision Tree\", y_test, y_pred_dt, \"Test Set\")\n",
    "print_model_metrics(\"Logistic Regression\", y_test, y_pred_lg, \"Test Set\")\n",
    "print_model_metrics(\"SVM\", y_test, y_pred_svm, \"Test Set\")\n",
    "print_model_metrics(\"Gradient Boosting\", y_test, y_pred_gbm, \"Test Set\")\n",
    "print_model_metrics(\"XGBoost\", y_test, y_pred_xgb, \"Test Set\")\n",
    "print_model_metrics(\"Stacking Classifier\", y_test, y_pred_stacking, \"Test Set\")\n",
    "\n",
    "# 打印训练集指标\n",
    "print_model_metrics(\"Random Forest\", y_train, y_pred_train_rf, \"Training Set\")\n",
    "print_model_metrics(\"Decision Tree\", y_train, y_pred_train_dt, \"Training Set\")\n",
    "print_model_metrics(\"Logistic Regression\", y_train, y_pred_train_lg, \"Training Set\")\n",
    "print_model_metrics(\"SVM\", y_train, y_pred_train_svm, \"Training Set\")\n",
    "print_model_metrics(\"Gradient Boosting\", y_train, y_pred_train_gbm, \"Training Set\")\n",
    "print_model_metrics(\"XGBoost\", y_train, y_pred_train_xgb, \"Training Set\")\n",
    "print_model_metrics(\"Stacking Classifier\", y_train, y_pred_train_stacking, \"Training Set\")\n",
    "\n",
    "# 保存所有模型的测试集结果，按分类保存\n",
    "for model_name, y_pred_proba, y_pred in zip(\n",
    "    ['RandomForest', 'DecisionTree', 'LogisticRegression', 'SVM', 'GBM', 'XGBoost', 'StackingClassifier'],\n",
    "    [y_pred_proba_rf, y_pred_proba_dt, y_pred_proba_lg, y_pred_proba_svm, y_pred_proba_gbm, y_pred_proba_xgb, y_pred_proba_stacking],\n",
    "    [y_pred_rf, y_pred_dt, y_pred_lg, y_pred_svm, y_pred_gbm, y_pred_xgb, y_pred_stacking]\n",
    "):\n",
    "    # 创建模型目录\n",
    "    model_dir = os.path.join(results_dir, \"test\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # 保存原始预测结果\n",
    "    custom_name = f'LF-SML-{model_name}(test)'\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_true.npy'), y_test)\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_proba.npy'), y_pred_proba)\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_pred.npy'), y_pred)\n",
    "    print(f\"已保存 {custom_name} 模型的测试集原始结果\")\n",
    "    \n",
    "    # 按分类保存预测结果\n",
    "    for class_idx, class_name in enumerate(unique_classes):\n",
    "        class_dir = os.path.join(model_dir, f\"class_{class_name}\")\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        \n",
    "        # 为当前类别创建二分类标签\n",
    "        y_true_binary = (y_test == class_name).astype(int)\n",
    "        y_pred_binary = (y_pred == class_name).astype(int)\n",
    "        y_proba_binary = y_pred_proba[:, class_idx]\n",
    "        \n",
    "        # 保存二分类结果\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_true.npy'), y_true_binary)\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_proba.npy'), y_proba_binary)\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_pred.npy'), y_pred_binary)\n",
    "        print(f\"已保存 {custom_name} 模型类别 {class_name} 的测试集二分类结果\")\n",
    "\n",
    "# 保存所有模型的训练集结果，按分类保存\n",
    "for model_name, y_pred_proba, y_pred in zip(\n",
    "    ['RandomForest', 'DecisionTree', 'LogisticRegression', 'SVM', 'GBM', 'XGBoost', 'StackingClassifier'],\n",
    "    [y_pred_proba_train_rf, y_pred_proba_train_dt, y_pred_proba_train_lg, y_pred_proba_train_svm, y_pred_proba_train_gbm, y_pred_proba_train_xgb, y_pred_proba_train_stacking],\n",
    "    [y_pred_train_rf, y_pred_train_dt, y_pred_train_lg, y_pred_train_svm, y_pred_train_gbm, y_pred_train_xgb, y_pred_train_stacking]\n",
    "):\n",
    "    # 创建模型目录\n",
    "    model_dir = os.path.join(results_dir, \"train\", model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # 保存原始预测结果\n",
    "    custom_name = f'LF-SML-{model_name}(train)'\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_true.npy'), y_train)\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_proba.npy'), y_pred_proba)\n",
    "    np.save(os.path.join(model_dir, f'{custom_name}_y_pred.npy'), y_pred)\n",
    "    print(f\"已保存 {custom_name} 模型的训练集原始结果\")\n",
    "    \n",
    "    # 按分类保存预测结果\n",
    "    for class_idx, class_name in enumerate(unique_classes):\n",
    "        class_dir = os.path.join(model_dir, f\"class_{class_name}\")\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "        \n",
    "        # 为当前类别创建二分类标签\n",
    "        y_true_binary = (y_train == class_name).astype(int)\n",
    "        y_pred_binary = (y_pred == class_name).astype(int)\n",
    "        y_proba_binary = y_pred_proba[:, class_idx]\n",
    "        \n",
    "        # 保存二分类结果\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_true.npy'), y_true_binary)\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_proba.npy'), y_proba_binary)\n",
    "        np.save(os.path.join(class_dir, f'{custom_name}_class{class_name}_y_pred.npy'), y_pred_binary)\n",
    "        print(f\"已保存 {custom_name} 模型类别 {class_name} 的训练集二分类结果\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
